# ğŸ¤– Agente Financeiro Inteligente com IA Generativa â€” **San (Multiagente)**

## Contexto

Os assistentes virtuais no setor financeiro estÃ£o evoluindo de simples chatbots reativos para **agentes inteligentes e proativos**. Este projeto implementa o **San**, um agente financeiro multi-modo que usa IA Generativa para:

* **Antecipar necessidades** (roteamento automÃ¡tico por intenÃ§Ã£o)
* **Personalizar** orientaÃ§Ãµes com base no contexto do cliente (perfil + transaÃ§Ãµes + histÃ³rico)
* **Cocriar soluÃ§Ãµes** com linguagem simples (educaÃ§Ã£o + plano prÃ¡tico)
* **Garantir seguranÃ§a** (anti-golpe + anti-alucinaÃ§Ã£o + regras e validaÃ§Ã£o final)

O San opera em **3 personas**:

* ğŸ›¡ï¸ **GuardiÃ£o:** anti-golpe / anti-fraude (prioridade mÃ¡xima)
* ğŸ“š **FinanÃ§as:** educaÃ§Ã£o financeira didÃ¡tica, sem recomendar investimentos especÃ­ficos
* ğŸ§­ **Autopiloto:** planejamento e organizaÃ§Ã£o de orÃ§amento com base em transaÃ§Ãµes

---

## VisÃ£o Geral do Projeto

### O problema que resolve

Clientes frequentemente:

* caem em golpes (WhatsApp/SMS/ligaÃ§Ã£o falsa, taxa de liberaÃ§Ã£o, pedido de cÃ³digo);
* nÃ£o entendem conceitos bÃ¡sicos de finanÃ§as e tomam decisÃµes impulsivas;
* nÃ£o conseguem controlar gastos e manter reserva.

### A soluÃ§Ã£o

O San combina:

* **LangGraph** (fluxo consistente): `router â†’ build_prompt â†’ LLM â†’ checker`
* **Ollama** (LLM local): roda modelos leves com baixo custo e bom desempenho
* **Streamlit**: interface de chat rÃ¡pida e simples
* **Base mock (CSV/JSON)**: dados sintÃ©ticos do cliente para personalizar as respostas

---

## Como Rodar

### Requisitos

* Python 3.10+
* Ollama instalado e rodando
* DependÃªncias Python (Streamlit, requests, pandas, langgraph)

### 1) Preparar ambiente

```bash
pip install -r requirements.txt
```

### 2) Baixar um modelo leve no Ollama (recomendado)

Modelo recomendado (baixo custo SSD e bom desempenho):

```bash
ollama pull llama3.2
```

> Alternativa ainda mais leve: `gemma2:2b` (se SSD estiver muito apertado).

### 3) Configurar caminho do dataset (opcional)

O projeto pode ler os datasets a partir de um caminho fixo no Windows. Exemplo:

```python
BASE_DATA = Path(r"D:\Pessoal\Secular\Machine Learning\protÃ³tipo_bia\dio-lab-bia-do-futuro\data")
```

Ou via variÃ¡vel de ambiente (recomendado):

**PowerShell**

```powershell
setx BIA_DATA_DIR "D:\Pessoal\Secular\Machine Learning\protÃ³tipo_bia\dio-lab-bia-do-futuro\data"
```

### 4) Rodar o app

```bash
streamlit run src/app.py
```

---

## Troca de Modelo e Economia de SSD

### Remover modelo antigo do Ollama (ex.: `gpt-oss`)

```bash
ollama list
ollama rm gpt-oss
```

### Baixar modelo novo

```bash
ollama pull llama3.2
```

### Trocar o modelo no cÃ³digo

No `src/app.py`, altere:

```python
MODELO = "llama3.2"
```

---

## O Que VocÃª Deve Entregar (como este repo resolve)

### 1. DocumentaÃ§Ã£o do Agente âœ…

* Caso de uso, persona/tom de voz, arquitetura e seguranÃ§a.
  ğŸ“„ `docs/01-documentacao-agente.md`

### 2. Base de Conhecimento âœ…

* Uso de dataset mock (CSV/JSON), reduÃ§Ã£o de contexto e filtros por agente.
  ğŸ“„ `docs/02-base-conhecimento.md`

### 3. Prompts do Agente âœ…

* 3 System Prompts (GuardiÃ£o, FinanÃ§as, Autopiloto), exemplos e edge cases.
  ğŸ“„ `docs/03-prompts.md`

### 4. AplicaÃ§Ã£o Funcional âœ…

* Chat em Streamlit + Ollama + LangGraph.
  ğŸ“ `src/`

### 5. AvaliaÃ§Ã£o e MÃ©tricas âœ…

* MÃ©tricas de roteamento, seguranÃ§a, consistÃªncia, uso do contexto e latÃªncia.
  ğŸ“„ `docs/04-metricas.md`

### 6. Pitch âœ…

* Roteiro do pitch de 3 minutos + checklist e link.
  ğŸ“„ `docs/05-pitch.md`

---

## Arquitetura (resumo)

O fluxo Ã© controlado pelo **LangGraph** para manter consistÃªncia de comportamento:

1. `router`: escolhe o agente com base na mensagem (GuardiÃ£o tem prioridade)
2. `build_prompt`: monta o prompt com system prompt + contexto (CSV/JSON), aplicando filtros por agente
3. `llm`: chama Ollama (`/api/generate`)
4. `checker`: reforÃ§a regras finais (mÃ¡x. 3 parÃ¡grafos, reforÃ§o anti-sensÃ­vel)

---

## Ferramentas Usadas

| Categoria    | Ferramentas       |
| ------------ | ----------------- |
| Interface    | Streamlit         |
| LLM local    | Ollama            |
| OrquestraÃ§Ã£o | LangGraph         |
| Dados        | CSV/JSON + pandas |
| HTTP         | requests          |

---

## Estrutura do RepositÃ³rio

> ObservaÃ§Ã£o: no projeto final, os datasets podem estar em `data/` ou em uma pasta externa configurada por caminho (ex.: `BIA_DATA_DIR`).

```
ğŸ“ lab-agente-financeiro/
â”‚
â”œâ”€â”€ ğŸ“„ README.md
â”‚
â”œâ”€â”€ ğŸ“ data/                          # Dados mockados (opcional/local)
â”‚   â”œâ”€â”€ historico_atendimento.csv
â”‚   â”œâ”€â”€ perfil_investidor.json
â”‚   â”œâ”€â”€ produtos_financeiros.json
â”‚   â””â”€â”€ transacoes.csv
â”‚
â”œâ”€â”€ ğŸ“ docs/
â”‚   â”œâ”€â”€ 01-documentacao-agente.md
â”‚   â”œâ”€â”€ 02-base-conhecimento.md
â”‚   â”œâ”€â”€ 03-prompts.md
â”‚   â”œâ”€â”€ 04-metricas.md
â”‚   â””â”€â”€ 05-pitch.md
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â””â”€â”€ app.py
â”‚
â””â”€â”€ ğŸ“ examples/
    â””â”€â”€ README.md
```

---

## Dicas Finais

1. **SeguranÃ§a primeiro:** qualquer sinal de golpe deve ser tratado pelo GuardiÃ£o.
2. **Contexto enxuto:** reduzir CSV/JSON melhora qualidade e latÃªncia.
3. **ConsistÃªncia com LangGraph:** o fluxo reduz â€œmudanÃ§a de personalidadeâ€ e aumenta previsibilidade.
4. **Teste cenÃ¡rios reais:** use prompts de golpe, educaÃ§Ã£o e orÃ§amento para validar roteamento e regras.
5. **Cuide do SSD:** remova modelos antigos com `ollama rm` e prefira modelos menores.


